{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qs 1.1\n",
    " # We have used pydub for manipulating audio files \n",
    " # pip install pydub\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "import sys\n",
    "import os\n",
    "base_path = os.getcwd()\n",
    "\n",
    "\n",
    "genre = \"Full-On\"  # Input name of the genre you want to preprocess\n",
    "\n",
    "path = base_path+\"\\\\\"+genre\n",
    "\n",
    "if os.path.exists(path)== True:       \n",
    "    files = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if '.wav' in file:\n",
    "                files.append(os.path.join(r, file))\n",
    "    i=0\n",
    "    dirc = path + \"\\\\chunks\"\n",
    "    if not os.path.exists(dirc):\n",
    "            os.makedirs(dirc)\n",
    "    for f in files:\n",
    "        \n",
    "        print(f)\n",
    "        myaudio = AudioSegment.from_file(f , \"wav\") \n",
    "        chunk_length_ms = 30000 # pydub calculates in millisec\n",
    "        chunks = make_chunks(myaudio, chunk_length_ms) # Make chunks of 30 secs\n",
    "        \n",
    "        for ind, chunk in enumerate(chunks):\n",
    "            \n",
    "            chunk_name = dirc + \"\\chunk{0}.wav\".format(i)\n",
    "            print(chunk_name)\n",
    "            chunk.export(chunk_name, format=\"wav\")\n",
    "            i = i+1\n",
    "else:\n",
    "    print(\"Directory doesn't exist!\") # If genre doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qs 1.2.1 Standard features using existing libraries :\n",
    "\n",
    "#pip install librosa\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "\n",
    "base_path = os.getcwd()\n",
    "genre = \"Hi_Tech\"  # Input the name of genre that you want to extract features from.\n",
    "\n",
    "\n",
    "path = base_path+\"\\\\\"+ genre+ \"\\\\chunks\"\n",
    "print(path)\n",
    "\n",
    "if os.path.exists(path)== True:\n",
    "\n",
    "    files = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if '.wav' in file:\n",
    "                files.append(os.path.join(r, file))\n",
    "    i = 0\n",
    "    file_names, Mfcc, Spec_BW, Spec_cnt, Spec_roll, Mel_spec = [], [], [], [], [], []\n",
    "    for f in files:\n",
    "        \n",
    "        print(i)\n",
    "        y, sr = librosa.load(f)\n",
    "        \n",
    "        mfcc_ = librosa.feature.mfcc(y=y, sr=sr)    # Feature 1 Mel Frequency Cepstral Coeff\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr)  # Feature 2 Mel Spectogram\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)    # Feature 3 Spectral bandwidth\n",
    "        spec_cnt = librosa.feature.spectral_centroid(y=y, sr=sr)    # Feature 4 Spectral Centroid\n",
    "        spec_roll = librosa.feature.spectral_rolloff(y=y, sr=sr)     # Feature 5 Spectral Rolloff\n",
    "        \n",
    "        # Qs. 1.3 part 1 :\n",
    "        # Normalizing features to zero mean and unit variance\n",
    "        mfcc_norm =  preprocessing.scale(mfcc_)\n",
    "        mel_spec_norm =  preprocessing.scale(mel_spec)\n",
    "        mel_spec_norm =  preprocessing.scale(mel_spec)\n",
    "        spec_bw_norm =  preprocessing.scale(spec_bw)\n",
    "        spec_cnt_norm =  preprocessing.scale(spec_cnt)\n",
    "        spec_roll_norm =  preprocessing.scale(spec_roll)\n",
    "        \n",
    "        # Appending features of individual chunks to create a list of 5 feature vectors \n",
    "        file_names.append(f)\n",
    "        Mfcc.append(mfcc_norm)\n",
    "        Mel_spec.append(mel_spec_norm)\n",
    "        Spec_BW.append(spec_bw_norm)\n",
    "        Spec_cnt.append(spec_cnt_norm)\n",
    "        Spec_roll.append(spec_roll_norm)\n",
    "        i=i+1\n",
    "    \n",
    "    # Qs. 1.2.3 \n",
    "    # Storing the extracted features to a csv file\n",
    "    df = pd.DataFrame(list(zip(file_names, Mfcc, Mel_spec, Spec_BW, Spec_cnt, Spec_roll)), \n",
    "               columns =['Filename', 'mfcc', \"mel_spectogram\",\"Spectral_bandwidth\",\"Spectral_centroid\",\"Spectral_rolloff\"]) \n",
    "        \n",
    "    df_name = genre + \"-features\"\n",
    "    df.to_csv(df_name+\".csv\",index=False)   \n",
    "\n",
    "    print(\"Features created for {Genre}\".format(Genre = genre))\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"Directory doesn't exist!\")\n",
    "    \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaled_df = scaler.fit_transform(mfcc_)\n",
    "mfcc_norm =  preprocessing.scale(mfcc_)\n",
    "scaled_df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qs 1.2.1 Kalman Filter for Beat Estimation :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qs 1.2.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qs 1.3 part 2, Dividing data into training and testing set (75:25)\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_name = ['Goa-features', 'Full-On-features', 'Dark_Forest-features', 'Hi_Tech-features']\n",
    "\n",
    "for i in range(len(df_name)):  # Assuming the files exist since we created them in the previous segment\n",
    "    train = []\n",
    "    test = []\n",
    "    df_read = pd.read_csv(df_name[i]+\".csv\", sep=',',header=None)\n",
    "    df = df_read.values\n",
    "    train, test = np.split(df, [int(0.75*len(df))])   # Splitting into 75:25 ratio\n",
    "    # writing to csv files for train and test set. \n",
    "    pd.DataFrame(train).to_csv(df_name[i]+\"-train.csv\", header=False, index=False) \n",
    "    pd.DataFrame(test).to_csv(df_name[i]+\"-test.csv\", header=False, index=False)\n",
    "#     np.savetxt(df_name[i]+\"-train.csv\", train, delimiter=\",\", fmt='%s')\n",
    "#     np.savetxt(df_name[i]+\"-test.csv\", test, delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
